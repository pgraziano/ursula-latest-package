# {{ ansible_managed }}

[DEFAULT]
# Terminate after detecting deprecated options
fatal_deprecations = {{ nova.enable_fatal_deprecations }}

# Paths to important items #
state_path = {{ nova.state_path }}
rootwrap_config = /etc/nova/rootwrap.conf
api_paste_config = /etc/nova/api-paste.ini

# APIs #
enabled_apis = osapi_compute,metadata
osapi_compute_listen_port = {{ endpoints.nova.port.backend_api }}

# Workers #
osapi_compute_workers = {{ nova.api_workers }}
metadata_workers = {{ nova.metadata_api_workers }}

# Policy #
allow_resize_to_same_host = True

# Logging #
log_dir = /var/log/nova
debug = {{ nova.logging.debug }}
use_stderr = false

# Scheduler #
{% if nova.custom_disk_filter.enabled|bool -%}
scheduler_available_filters = nova.scheduler.filters.all_filters
scheduler_available_filters = bbc_openstack_plugins.nova.scheduler.filters.bbc_disk_filter.BBCDiskFilter
reserved_host_disk_ratio = {{ nova.custom_disk_filter.reserved_ratio }}
{% endif -%}
scheduler_default_filters = {{ nova.scheduler_default_filters }}{{ ',BBCDiskFilter' if nova.custom_disk_filter.enabled|bool else '' }}
scheduler_host_subset_size = {{ nova.scheduler_host_subset_size }}

{% if nova.default_availability_zone is defined -%}
default_schedule_zone = {{ nova.default_availability_zone }}
{% endif -%}

{% if ironic.enabled -%}
scheduler_host_manager = ironic_host_manager
cpu_allocation_ratio = 1.0
ram_allocation_ratio = 1.0
{% else -%}
scheduler_host_manager = {{ nova.scheduler_host_manager }}
cpu_allocation_ratio = {{ nova.cpu_allocation_ratio }}
ram_allocation_ratio = {{ nova.ram_allocation_ratio }}
{% endif -%}

{% if groups['compute_power'] is undefined or inventory_hostname not in groups['compute_power'] %}
#Reserve CPUs for host OS on converged controllers and x86 compute hosts
{% set reserved_cores = 4 if inventory_hostname in groups['controller'] else 1 %}
{% set cpulimit = cpulimit | default((ansible_processor | count / 2) | int) %}
{% set cpu_core_count = cpulimit if cpulimit < (ansible_processor | count / 2) | int else (ansible_processor | count / 2) | int %}
{% if cpu_core_count > reserved_cores %}
vcpu_pin_set = "{{ reserved_cores }}-{{ cpu_core_count - 1 }}"
{% endif -%}
{% endif -%}

# Services offered #
cc_host={{ endpoints.main }}

my_ip = {{ hostvars[inventory_hostname][primary_interface]['ipv4']['address'] }}

# Networking #
use_neutron = True
firewall_driver = nova.virt.firewall.NoopFirewallDriver
default_floating_pool = {{ nova.floating_pool }}

# Cinder #
block_device_allocate_retries = {{ nova.block_device_allocate_retries }}
block_device_allocate_retries_interval = {{ nova.block_device_allocate_retries_interval }}

# Reserved Resources #
{% if ironic.enabled -%}
reserved_host_memory_mb = 0
{% elif nova.reserved_host_memory_mb is defined %}
reserved_host_memory_mb = {{ nova.reserved_host_memory_mb }}
{% elif inventory_hostname in groups['controller'] and nova.controller_reserve_ram is defined -%}
reserved_host_memory_mb = {{ nova.controller_reserve_ram }}
{% elif inventory_hostname in groups['compute'] and nova.compute_reserve_ram is defined -%}
reserved_host_memory_mb = {{ nova.compute_reserve_ram }}
{% endif %}
reserved_host_disk_mb = {{ nova.reserved_host_disk_mb }}

# Misc #
compute_driver = {{ nova.compute_driver }}
resume_guests_state_on_host_boot = True

preallocate_images = {{ nova.preallocate_images }}

[workarounds]
disable_libvirt_livesnapshot = False

[api_database]
connection = mysql+pymysql://nova_api:{{ secrets.db_password }}@{{ endpoints.db }}/nova_api?charset=utf8

[cinder]
catalog_info = volumev2:cinderv2:publicURL
cafile = {{ nova.cafile }}
os_region_name = RegionOne

[conductor]
workers = {{ nova.conductor_workers }}

[database]
connection = mysql+pymysql://nova:{{ secrets.db_password }}@{{ endpoints.db }}/nova?charset=utf8

[glance]
api_servers = {{ nova.glance_endpoint }}

{% if ironic.enabled -%}
[ironic]
api_endpoint = {{ endpoints.ironic.url.internal }}/{{ endpoints.ironic.version }}
admin_url = {{ endpoints.keystone.url.public }}/{{ endpoints.keystone.version }}
auth_type = password
admin_username = ironic
admin_password = {{ secrets.service_password }}
admin_tenant_name = service
{% if insecure|default('False')|bool %}
insecure = true
{% endif %}
{% endif -%}

[keystone_authtoken]
auth_url = {{ endpoints.keystone.url.admin }}
auth_uri = {{ endpoints.keystone.url.internal }}
cafile = {{ nova.cafile }}
signing_dir = /var/cache/nova/api
memcached_servers = {{ hostvars|ursula_memcache_hosts(groups, memcached.port) }}
auth_type = password
project_domain_id = default
project_name = service
user_domain_id = default
username = nova
password = {{ secrets.service_password }}
{% if insecure|default('False')|bool %}
insecure = true
{% endif %}

[api_database]
connection=mysql+pymysql://nova_api:{{ secrets.db_password }}@{{ endpoints.db }}/nova_api?charset=utf8

[libvirt]
virt_type={{ nova.libvirt_type }}
{% if nova.libvirt_cpu_model -%}
cpu_mode = custom
cpu_model = {{ nova.libvirt_cpu_model }}
{% elif (nova.libvirt_cpu_model and ansible_architecture == "ppc64le") or nova.enable_numa %}
cpu_mode = host-passthrough
{% else %}
cpu_mode = {{ nova.libvirt_cpu_mode }}
{% endif -%}
live_migration_downtime = 500
live_migration_downtime_steps = 10
live_migration_downtime_delay = 75
live_migration_uri = "qemu+ssh://nova@%s/system?keyfile={{ nova.state_path }}/.ssh/id_rsa"

# Reserved Resources
{% if ironic.enabled -%}
reserved_host_memory_mb = 0
{% elif inventory_hostname in groups['controller'] -%}
reserved_host_memory_mb = 4096
{% endif %}
disk_cachemodes = "network=writeback"

{% if v7k.enabled %}
{% if v7k.multipath.enabled %}
iscsi_use_multipath = True
{% endif %}
{% endif %}


[neutron]
url = {{ endpoints.neutron.url.internal }}
auth_url = {{ endpoints.keystone.url.admin}}
auth_type = password
cafile = {{ nova.cafile }}
region_name = RegionOne
project_domain_id = default
project_name = service
user_domain_id = default
username = neutron
password = {{ secrets.service_password }}
{% if insecure|default('False')|bool %}
insecure = true
{% endif %}

service_metadata_proxy = True
metadata_proxy_shared_secret = {{ secrets.metadata_proxy_shared_secret }}

[oslo_concurrency]
# If on a host that runs cinder, a shared lock path is needed between
# nova and cinder for os-brick reasons. So we always use a shared location
lock_path = {{ state_path_base }}/sharedlock

[oslo_messaging_rabbit]
{% macro rabbitmq_hosts() -%}
{% for host in groups['controller'] -%}
   {% if loop.last -%}
{{ hostvars[host][primary_interface]['ipv4']['address'] }}:{{ rabbitmq.port }}
   {%- else -%}
{{ hostvars[host][primary_interface]['ipv4']['address'] }}:{{ rabbitmq.port }},
   {%- endif -%}
{% endfor -%}
{% endmacro -%}

heartbeat_timeout_threshold = {{ nova.heartbeat_timeout_threshold }}
{% if rabbitmq.cluster -%}
rabbit_hosts = {{ rabbitmq_hosts() }}
{% else -%}
rabbit_host = {{ endpoints.rabbit }}
{% endif -%}
rabbit_userid = {{ rabbitmq.user }}
rabbit_password = {{ secrets.rabbit_password }}

{% if nova.auditing.enabled|bool and nova.auditing.logging|bool %}
[oslo_messaging_notifications]
# Store pyCADF audit events in log #
driver = log
{% endif %}

[oslo_middleware]
enable_proxy_headers_parsing = True

[placement]
auth_url = {{ endpoints.keystone.url.admin }}/{{ endpoints.keystonev3.version }}
auth_type = password
username = placement
password = {{ secrets.service_password }}
cafile = {{ nova.cafile }}
project_name = service
project_domain_id = default
os_region_name = RegionOne
user_domain_id = default
{% if insecure|default('False')|bool %}
insecure = true
{% endif %}

[cache]
backend = oslo_cache.memcache_pool
enabled = True
memcache_servers = {{ hostvars|ursula_memcache_hosts(groups, memcached.port) }}

[vnc]
vncserver_proxyclient_address = {{ primary_ip }}
vncserver_listen = {{ primary_ip }}

enabled = {{ nova.enable_novnc }}
novncproxy_base_url= {{ endpoints.novnc.url.internal }}/vnc_auto.html
novncproxy_port = {{ endpoints.novnc.port.backend_api }}
keymap={{ nova.vnc_keymap }}

# Temporarily define helper commands, until
# https://bugs.launchpad.net/nova/+bug/1616240 is fixed
[vif_plug_linux_bridge_privileged]
helper_command = sudo nova-rootwrap $rootwrap_config privsep-helper --config-file /etc/nova/nova.conf

[privsep_osbrick]
helper_command = sudo nova-rootwrap $rootwrap_config privsep-helper --config-file /etc/nova/nova.conf

[upgrade_levels]
compute=auto
